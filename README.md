# ğŸ“Š Data Warehouse Project â€” [Project Name]

## ğŸ§  Overview

This project implements an end-to-end **Data Warehousing solution** that transforms raw operational data into structured analytical data for reporting and decision making.

The pipeline extracts data from source systems, cleans and transforms it using ETL processes, and loads it into a dimensional model (Star Schema) optimized for analytics.

> ğŸ¯ Objective: Convert raw transactional data into meaningful business insights.

---

## ğŸ—ï¸ Architecture

```
Source Systems â†’ Staging Layer â†’ ETL Transformation â†’ Data Warehouse â†’ BI / Analytics
```

### Data Flow

1. Raw data collected from source systems
2. Loaded into staging tables
3. Cleaned & transformed using ETL logic
4. Loaded into dimensional warehouse tables
5. Queried for reporting & analysis

---

## ğŸ› ï¸ Tech Stack

| Category        | Tools Used                              |
| --------------- | --------------------------------------- |
| Database        | [SQL Server / Oracle / PostgreSQL]      |
| ETL             | [SSIS / Python / SQL Stored Procedures] |
| Data Modeling   | Star Schema                             |
| Visualization   | [Power BI / Tableau / None]             |
| Language        | SQL, Python                             |
| Version Control | Git & GitHub                            |

---

## ğŸ“‚ Project Structure

```
data-warehouse-project/
â”‚
â”œâ”€â”€ datasets/              # Raw input data files
â”œâ”€â”€ staging/               # Staging table creation scripts
â”œâ”€â”€ warehouse/             # Fact & Dimension table scripts
â”œâ”€â”€ etl/                   # ETL procedures / pipelines
â”œâ”€â”€ transformations/       # Data cleaning & transformation logic
â”œâ”€â”€ analytics/             # Business queries & reports
â”œâ”€â”€ docs/                  # Architecture & schema diagrams
â””â”€â”€ README.md
```

---

## ğŸ—„ï¸ Data Model (Star Schema)

### Fact Tables

* **Fact_Sales**

  * sale_id
  * customer_key
  * product_key
  * date_key
  * quantity
  * total_amount

### Dimension Tables

* **Dim_Customer**
* **Dim_Product**
* **Dim_Date**
* **Dim_Location**

---

## âš™ï¸ ETL Process

### 1ï¸âƒ£ Extract

Data extracted from:

* CSV files
* Operational database
* External data sources

### 2ï¸âƒ£ Transform

Transformations performed:

* Null handling
* Duplicate removal
* Data type standardization
* Surrogate key generation
* Slowly Changing Dimension handling (SCD)

### 3ï¸âƒ£ Load

Loading order:

1. Dimension tables
2. Fact tables

---

## ğŸ“ˆ Sample Business Queries

```sql
-- Top selling products
SELECT p.product_name, SUM(f.total_amount) AS revenue
FROM Fact_Sales f
JOIN Dim_Product p ON f.product_key = p.product_key
GROUP BY p.product_name
ORDER BY revenue DESC;
```

---

## ğŸ“Š Insights Generated

The warehouse supports analysis such as:

* Monthly revenue trends
* Customer purchase behavior
* Best performing products
* Regional sales performance

---

## ğŸš€ How to Run the Project

### Step 1 â€” Create Database

```sql
CREATE DATABASE DataWarehouse;
```

### Step 2 â€” Execute Scripts

1. Run staging table scripts
2. Run dimension table scripts
3. Run fact table scripts
4. Execute ETL scripts

### Step 3 â€” Run Analytics Queries

Use queries located in `analytics/queries.sql`

---

## ğŸ“Œ Concepts Implemented

* Data Cleaning
* Surrogate Keys
* Star Schema Modeling
* Fact & Dimension Tables
* ETL Pipeline
* Aggregations
* Business Intelligence Queries

---

## ğŸ§© Future Improvements

* Incremental data loading
* Change Data Capture (CDC)
* Automated ETL scheduling
* Dashboard integration

---

## ğŸ‘¨â€ğŸ’» Author

**Chamidu Gunathunga**
Aspiring Data Engineer ğŸš€

